{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport cv2\nimport os\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model\nfrom skimage import color","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-14T08:26:09.411949Z","iopub.execute_input":"2022-03-14T08:26:09.412650Z","iopub.status.idle":"2022-03-14T08:26:12.202169Z","shell.execute_reply.started":"2022-03-14T08:26:09.412513Z","shell.execute_reply":"2022-03-14T08:26:12.201409Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Take entire data in a batch\nprint(os.listdir('/kaggle/input'))\nTRAIN_BATCH_SIZE = len(os.listdir('/kaggle/input/landscape-pictures'))\nTEST_BATCH_SIZE = len(os.listdir('/kaggle/input/image-colorization-dataset/data/test_color'))\n\nprint(TRAIN_BATCH_SIZE, TEST_BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T08:26:12.204040Z","iopub.execute_input":"2022-03-14T08:26:12.204410Z","iopub.status.idle":"2022-03-14T08:26:12.263266Z","shell.execute_reply.started":"2022-03-14T08:26:12.204367Z","shell.execute_reply":"2022-03-14T08:26:12.262526Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"BASE_PATH = '/kaggle/input/'\n\ntrain_datagen = ImageDataGenerator(\n    rescale = 1/255.0\n)\n\ntrain_data = train_datagen.flow_from_directory(\n    BASE_PATH,\n    classes=['landscape-pictures'],\n    target_size = (224,224),\n    batch_size = TRAIN_BATCH_SIZE\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T08:26:12.264519Z","iopub.execute_input":"2022-03-14T08:26:12.264784Z","iopub.status.idle":"2022-03-14T08:26:13.526410Z","shell.execute_reply.started":"2022-03-14T08:26:12.264749Z","shell.execute_reply":"2022-03-14T08:26:13.525638Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"X = [] #grayscale images\ny = [] #ground truth for X (other 2 channels)\ni = 0\nfor image in train_data.next()[0]:\n    image = color.rgb2lab(image)\n    X.append(image[:, :, 0].reshape(224,224,1))\n    y.append(image[:, :, 1:]/128)\n    i += 1\n\nX = np.array(X)\ny = np.array(y)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T08:26:13.529239Z","iopub.execute_input":"2022-03-14T08:26:13.529836Z","iopub.status.idle":"2022-03-14T08:28:06.698554Z","shell.execute_reply.started":"2022-03-14T08:26:13.529805Z","shell.execute_reply":"2022-03-14T08:28:06.697711Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(X.shape, y.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T08:28:06.699897Z","iopub.execute_input":"2022-03-14T08:28:06.700146Z","iopub.status.idle":"2022-03-14T08:28:06.707956Z","shell.execute_reply.started":"2022-03-14T08:28:06.700112Z","shell.execute_reply":"2022-03-14T08:28:06.707242Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def build_encoder():\n    encoder = keras.Sequential()\n    encoder.add(layers.Input(shape=(224, 224, 1)))\n    encoder.add(layers.Conv2D(64, (3,3), strides=2, padding='same', activation='relu'))\n    encoder.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n    encoder.add(layers.Conv2D(128, (3,3), strides= 2, padding='same', activation='relu'))\n    encoder.add(layers.Conv2D(256, (3,3), padding='same', activation='relu'))\n    encoder.add(layers.Conv2D(256, (3,3), strides= 2, padding='same', activation='relu'))\n    encoder.add(layers.Conv2D(512, (3,3), padding='same', activation='relu'))\n    encoder.add(layers.Conv2D(512, (3,3), padding='same', activation='relu'))\n    encoder.add(layers.Conv2D(512, (3,3), padding='same', activation='relu'))\n    encoder.add(layers.Conv2D(256, (3,3), padding='same', activation='relu'))\n\n    # Decoder stage\n    encoder.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n    encoder.add(layers.UpSampling2D(size=(2,2)))\n    encoder.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n    encoder.add(layers.Conv2D(32, (3,3), padding='same', activation='relu'))\n\n    encoder.add(layers.UpSampling2D(size=(2,2)))\n    encoder.add(layers.Conv2D(16, (3,3), padding='same', activation='relu'))\n    encoder.add(layers.Conv2D(2, (3,3), padding='same', activation='tanh'))\n    encoder.add(layers.UpSampling2D(size=(2,2)))\n    \n    return encoder\nmodel = build_encoder()\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=5, min_lr=0.001)\n\nmodel.compile(optimizer='adam', metrics=['acc'], loss='mean_squared_error')\nhistory = model.fit(X, y, epochs = 50, batch_size = 64, steps_per_epoch = X.shape[0]//64, validation_split = 0.3, verbose = 1, callbacks=[reduce_lr])","metadata":{"execution":{"iopub.status.busy":"2022-03-14T08:28:06.709305Z","iopub.execute_input":"2022-03-14T08:28:06.709806Z","iopub.status.idle":"2022-03-14T08:40:31.296403Z","shell.execute_reply.started":"2022-03-14T08:28:06.709767Z","shell.execute_reply":"2022-03-14T08:40:31.295558Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"test_data = train_datagen.flow_from_directory(\n    '/kaggle/input/image-colorization-dataset/data',\n    classes=[\"test_color\"],\n    target_size = (224,224),\n    batch_size = 64\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T08:40:31.299164Z","iopub.execute_input":"2022-03-14T08:40:31.299702Z","iopub.status.idle":"2022-03-14T08:40:31.409820Z","shell.execute_reply.started":"2022-03-14T08:40:31.299663Z","shell.execute_reply":"2022-03-14T08:40:31.409057Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"test_image_batch = test_data.next()\ntest_images = test_image_batch[0]","metadata":{"execution":{"iopub.status.busy":"2022-03-14T08:42:41.081027Z","iopub.execute_input":"2022-03-14T08:42:41.081299Z","iopub.status.idle":"2022-03-14T08:42:41.506394Z","shell.execute_reply.started":"2022-03-14T08:42:41.081270Z","shell.execute_reply":"2022-03-14T08:42:41.505626Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-14T08:44:06.377487Z","iopub.execute_input":"2022-03-14T08:44:06.378102Z","iopub.status.idle":"2022-03-14T08:44:06.574441Z","shell.execute_reply.started":"2022-03-14T08:44:06.378064Z","shell.execute_reply":"2022-03-14T08:44:06.573706Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"for image in test_images:\n    test_img = color.rgb2lab(image)\n    plt.figure(figsize=(8, 6), dpi=80)\n    plt.subplot(1,3,1)\n    gray = np.zeros((224, 224, 1))\n    gray[:,:,0] = test_img[:, :, 0]\n    plt.title(\"Graysacle Image\")\n    plt.imshow(gray, cmap='gray')\n    \n    plt.subplot(1,3,2)\n    pred = np.zeros((224, 224, 3))\n    pred[:,:,0] = test_img[:, :, 0]\n    ab = model.predict(test_img[:, :, 0].reshape((1,224,224,1))) \n    ab = ab*128\n    pred[:,:,1:] = ab\n    pred = color.lab2rgb(pred)\n    plt.title(\"Encoder Output\")\n    plt.imshow(pred)\n    \n    plt.subplot(1,3,3)\n    plt.title(\"Ground Truth\")\n    plt.imshow(color.lab2rgb(test_img))\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-14T08:42:42.633383Z","iopub.execute_input":"2022-03-14T08:42:42.633661Z","iopub.status.idle":"2022-03-14T08:43:11.761103Z","shell.execute_reply.started":"2022-03-14T08:42:42.633631Z","shell.execute_reply":"2022-03-14T08:43:11.760410Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"model.save(\"color.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-03-14T08:40:31.883625Z","iopub.execute_input":"2022-03-14T08:40:31.884084Z","iopub.status.idle":"2022-03-14T08:40:31.890180Z","shell.execute_reply.started":"2022-03-14T08:40:31.884051Z","shell.execute_reply":"2022-03-14T08:40:31.889456Z"},"trusted":true},"execution_count":10,"outputs":[]}]}